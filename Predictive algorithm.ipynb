{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eli5 in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: attrs>16.0.0 in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from eli5) (19.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from eli5) (1.3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from eli5) (2.10.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from eli5) (0.23.1)\n",
      "Requirement already satisfied: six in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from eli5) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from eli5) (1.16.5)\n",
      "Requirement already satisfied: graphviz in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from eli5) (0.14)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from eli5) (0.8.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from jinja2->eli5) (1.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->eli5) (0.13.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pallavim777\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->eli5) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from getpass import getpass\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import eli5\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the database password for lixpm28: ········\n"
     ]
    }
   ],
   "source": [
    "#Logging into the database with individual credentials\n",
    "user = 'lixpm28'\n",
    "db_ip = '10.158.72.23'\n",
    "pw = getpass('Enter the database password for {}: '.format(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function definition to return temporal holdout sets using all features\n",
    "def get_features( ref_day = 608-30, tumbling_window_size = 30, output_window_size = 30, num_periods = 7, window_agg_fun = 'SUM'):\n",
    "        sql_top = \"\"\"\n",
    "        SELECT cust,\n",
    "        %(ref_date)s AS ref_day,\n",
    "        (CASE WHEN SUM(CASE WHEN dayofpurchase > %(ref_date)s AND dayofpurchase <= %(ref_date)s+%(ows)s THEN 1 ELSE 0 END)>0 THEN 1 ELSE 0 END) as output_feature,\n",
    "        \"\"\"\n",
    "       \n",
    "        sql=sql_top\n",
    "#Creating temporal features to account for FREQUENCY of visits, QUANTITY of items, AMOUNT spent, GAP between consecutive visits\n",
    "        for i in range(0,num_periods):\n",
    "            sql += \"{2}(CASE WHEN dayofpurchase > %(ref_date)s -%(ws)s::INT*({0}+1) AND dayofpurchase <= %(ref_date)s-%(ws)s*({0}) THEN 1 ELSE 0 END ) as freq{1},\\n\".format(i, i+1, window_agg_fun)\n",
    "        for i in range(num_periods,num_periods*2):\n",
    "            sql += \"{2}(CASE WHEN dayofpurchase > %(ref_date)s -%(ws)s::INT*({0}+1) AND dayofpurchase <= %(ref_date)s-%(ws)s*({0}) THEN qty::INT ELSE 0 END ) as qty{1},\\n\".format(i, i+1, window_agg_fun)\n",
    "        for i in range(num_periods*2,num_periods*3):\n",
    "            sql += \"{2}(CASE WHEN dayofpurchase > %(ref_date)s -%(ws)s::INT*({0}+1) AND dayofpurchase <= %(ref_date)s-%(ws)s*({0}) THEN val ELSE 0 END ) as amt{1},\\n\".format(i, i+1, window_agg_fun)\n",
    "        for i in range(num_periods*3,num_periods*4):\n",
    "            sql += \"{2}(CASE WHEN dayofpurchase > %(ref_date)s -%(ws)s::INT*({0}+1) AND dayofpurchase <= %(ref_date)s-%(ws)s*({0}) THEN gap::INT ELSE 0 END ) as gap{1},\\n\".format(i, i+1, window_agg_fun)\n",
    "\n",
    "        sql_bottom = \"\"\"\n",
    "        FROM temp_features\n",
    "        GROUP BY cust\n",
    "        \"\"\"    \n",
    "        sql = sql[:-2] + sql_bottom\n",
    "        with psycopg2.connect(\"host='{}' dbname='nlab' user='{}' password='{}'\".format(db_ip, user, pw)) as conn:\n",
    "            df = pd.read_sql(sql, conn, params = {'ref_date':ref_day,'ws':tumbling_window_size, 'ows':output_window_size})\n",
    "            df=df.set_index('cust')\n",
    "            return df.drop(columns = ['ref_day','output_feature'], inplace = False), df.output_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to print variable importances\n",
    "def print_variable_importances( feature_names, dict_in, show_top = 10 ):\n",
    "  \"\"\"\n",
    "  Prints a table of feature importance scores.\n",
    "  \n",
    "  Keyword arguments\n",
    "  feature_names -- list of feature names. Must have the same ordering as the \n",
    "                   scores in each instance of list_of_scores (see below)\n",
    "  dict_in       -- dictionary of the form {method_name:list_of_scores} where:\n",
    "                   method_name    -- string\n",
    "                   list_of_scores -- list of scores, ordered in the same order\n",
    "                                     as the passed feature_names\n",
    "  show_top      -- number of features to show (default 10, None to print all)\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  # Implement the definition of None for show_top\n",
    "  if show_top is None:\n",
    "    show_top = len(feature_names)\n",
    "  \n",
    "  # Set up lists to hold the titles and score_feature tuples\n",
    "  # We need a list so that they maintain fixed order as we \n",
    "  # iterate over them row-by-row.\n",
    "  to_print_titles = []\n",
    "  to_print_scores = []\n",
    "  \n",
    "  # Pair each list of scores with a copy of the feature names and sort\n",
    "  # based on the variable importance score descending\n",
    "  for k, v in dict_in.items():\n",
    "    # zip pairs, sorted sorts, reverse orders descending\n",
    "    feature_names_plus_scores = sorted( zip(v, feature_names) )\n",
    "    feature_names_plus_scores.reverse()\n",
    "    to_print_titles.append(k)\n",
    "    to_print_scores.append(feature_names_plus_scores)\n",
    "    \n",
    "    \n",
    "  # Print the scores\n",
    "  \n",
    "  # Create a list of strings to print in each header cell\n",
    "  line_parts = []\n",
    "  for j in range(len(to_print_titles)):\n",
    "    line_parts.append('{:<38}'.format(to_print_titles[j]))\n",
    "  \n",
    "  # Print each header cell using a separator ' | ', adding the fixed rank column header \n",
    "  print('Rank | ' + ' | '.join( ['{:<38}'.format(x) for x in to_print_titles] ) )\n",
    "  \n",
    "  # Print the header underline\n",
    "  print('---- + ' + ' + '.join( [ '-'*38 ]*len(to_print_titles) ) )\n",
    "  \n",
    "  # Print each line\n",
    "  for i in range(show_top):\n",
    "    # Create a list of strings to print for each row cell\n",
    "    line_parts = []\n",
    "    for j in range(len(to_print_titles)):\n",
    "      line_parts.append(  '{:<30}: {:.4f}'.format(to_print_scores[j][i][1], to_print_scores[j][i][0]) )\n",
    "    # Print the row by:\n",
    "    # (1) joining each row cell using a separator ' | '\n",
    "    # (2) adding the fixed rank column header \n",
    "    print( '{:<4} | '.format(str(i)) + ' | '.join(line_parts) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['freq1', 'freq2', 'freq3', 'freq4', 'freq5', 'freq6', 'freq7', 'qty8',\n",
       "       'qty9', 'qty10', 'qty11', 'qty12', 'qty13', 'qty14', 'amt15', 'amt16',\n",
       "       'amt17', 'amt18', 'amt19', 'amt20', 'amt21', 'gap22', 'gap23', 'gap24',\n",
       "       'gap25', 'gap26', 'gap27', 'gap28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting holdout set to evaluate feature importance\n",
    "X, y = get_features(ref_day = 608-30, tumbling_window_size = 30, output_window_size = 30, num_periods = 7, window_agg_fun = 'SUM')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank | Perm non-cv RF (87.45)                \n",
      "---- + --------------------------------------\n",
      "0    | freq1                         : 0.0539\n",
      "1    | freq3                         : 0.0502\n",
      "2    | qty8                          : 0.0274\n",
      "3    | amt16                         : 0.0272\n",
      "4    | freq6                         : 0.0249\n",
      "5    | freq2                         : 0.0240\n",
      "6    | qty13                         : 0.0237\n",
      "7    | qty12                         : 0.0237\n",
      "8    | qty14                         : 0.0224\n",
      "9    | qty11                         : 0.0222\n",
      "10   | freq5                         : 0.0220\n",
      "11   | qty10                         : 0.0213\n",
      "12   | qty9                          : 0.0190\n",
      "13   | freq7                         : 0.0185\n",
      "14   | freq4                         : 0.0161\n",
      "15   | amt15                         : 0.0156\n",
      "16   | amt17                         : 0.0140\n",
      "17   | amt19                         : 0.0100\n",
      "18   | amt18                         : 0.0095\n",
      "19   | amt20                         : 0.0061\n",
      "20   | gap28                         : 0.0000\n",
      "21   | gap27                         : 0.0000\n",
      "22   | gap26                         : 0.0000\n",
      "23   | gap25                         : 0.0000\n",
      "24   | gap24                         : 0.0000\n",
      "25   | gap23                         : 0.0000\n",
      "26   | gap22                         : 0.0000\n",
      "27   | amt21                         : 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Calculating variable importances by permutation importance\n",
    "\n",
    "#Splitting into training and test datasets\n",
    "X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "#Creating classifier model\n",
    "rf_perm = RandomForestClassifier()\n",
    "\n",
    "rf_perm.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "perm = PermutationImportance(rf_perm, cv='prefit')\n",
    "\n",
    "perm.fit(X_test_sub, y_test_sub)\n",
    "\n",
    "\n",
    "#Making predictions, calculating scores\n",
    "y_pred = rf_perm.predict(X_test)\n",
    "scores = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calculating and displaying feature importances\n",
    "\n",
    "method_name = 'Perm non-cv RF ({:.2f})'.format(scores*100)\n",
    "\n",
    "feature_importance_scores = {}\n",
    "feature_importance_scores[method_name] = perm.feature_importances_\n",
    "eli5.show_weights(perm)\n",
    "\n",
    "print_variable_importances( X_train.columns, feature_importance_scores, show_top = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function definition to return temporal holdout sets using just the selected features\n",
    "def get_dataset( ref_day = 608-30, tumbling_window_size = 30, output_window_size = 30, num_periods = 7, window_agg_fun = 'SUM'):\n",
    "        sql_top = \"\"\"\n",
    "        SELECT cust,\n",
    "        %(ref_date)s AS ref_day,\n",
    "        (CASE WHEN SUM(CASE WHEN dayofpurchase > %(ref_date)s AND dayofpurchase <= %(ref_date)s+%(ows)s THEN 1 ELSE 0 END)>0 THEN 1 ELSE 0 END) as output_feature,\n",
    "        \"\"\"\n",
    "       \n",
    "        sql=sql_top\n",
    "#Creating temporal features to account for FREQUENCY of visits, QUANTITY of items, AMOUNT spent\n",
    "        for i in range(0,num_periods):\n",
    "            sql += \"{2}(CASE WHEN dayofpurchase > %(ref_date)s -%(ws)s::INT*({0}+1) AND dayofpurchase <= %(ref_date)s-%(ws)s*({0}) THEN 1 ELSE 0 END ) as freq{1},\\n\".format(i, i+1, window_agg_fun)\n",
    "        for i in range(num_periods,num_periods*2):\n",
    "            sql += \"{2}(CASE WHEN dayofpurchase > %(ref_date)s -%(ws)s::INT*({0}+1) AND dayofpurchase <= %(ref_date)s-%(ws)s*({0}) THEN qty::INT ELSE 0 END ) as qty{1},\\n\".format(i, i+1, window_agg_fun)\n",
    "        for i in range(num_periods*2,num_periods*3):\n",
    "            sql += \"{2}(CASE WHEN dayofpurchase > %(ref_date)s -%(ws)s::INT*({0}+1) AND dayofpurchase <= %(ref_date)s-%(ws)s*({0}) THEN val ELSE 0 END ) as amt{1},\\n\".format(i, i+1, window_agg_fun)\n",
    "\n",
    "        sql_bottom = \"\"\"\n",
    "        FROM temp_features\n",
    "        GROUP BY cust\n",
    "        \"\"\"    \n",
    "        sql = sql[:-2] + sql_bottom\n",
    "        with psycopg2.connect(\"host='{}' dbname='nlab' user='{}' password='{}'\".format(db_ip, user, pw)) as conn:\n",
    "            df = pd.read_sql(sql, conn, params = {'ref_date':ref_day,'ws':tumbling_window_size, 'ows':output_window_size})\n",
    "            df=df.set_index('cust')\n",
    "            return df.drop(columns = ['ref_day','output_feature'], inplace = False), df.output_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixpm28/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/lixpm28/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/lixpm28/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/lixpm28/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/lixpm28/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/lixpm28/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forest Classifiers ~ Acc. 0.7754410172806832 Recall: 0.8500225305418899 Specificity: 0.6523549303088922 Balanced: 0.7511887304253911 Precision: 0.8027067875808288\n",
      "For KNN Classifiers ~ Acc. 0.7338714285833624 Recall: 0.784603950769486 Specificity: 0.650475517892508 Balanced: 0.717539734330997 Precision: 0.7886680818695736\n",
      "For Linear SVC ~ Acc. 0.7457635323633144 Recall: 0.7349973321119975 Specificity: 0.767766017163513 Balanced: 0.7513816746377552 Precision: 0.8436390048231696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixpm28/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Training and assessment of classifier models\n",
    "\n",
    "output_window_size = 30 \n",
    "tumbling_window_size = 30\n",
    "total_holdout_sets = 7\n",
    "now =  608-output_window_size\n",
    "\n",
    "modelrf = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "modelknn = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "modelsvc = LinearSVC()\n",
    "\n",
    "#Creating empty lists to store accuracy scores across holdout sets\n",
    "accrf = []\n",
    "balrf = []\n",
    "recrf = []\n",
    "specrf = []\n",
    "precrf = []\n",
    "\n",
    "accknn = []\n",
    "balknn = []\n",
    "recknn = []\n",
    "specknn = []\n",
    "precknn = []\n",
    "\n",
    "accsvc = []\n",
    "balsvc = []\n",
    "recsvc = []\n",
    "specsvc = []\n",
    "precsvc = []\n",
    "\n",
    "#Iterations through holdout sets\n",
    "for i in range(total_holdout_sets):\n",
    "    test_X, test_y = get_dataset( now - output_window_size, tumbling_window_size, output_window_size )\n",
    "    test_X=test_X[test_X.freq1>0]\n",
    "    indices1=list(test_X[test_X.freq1>0].index.values)\n",
    "    test_y=test_y[test_y.index.isin(indices1)]\n",
    "    \n",
    "    train_X, train_y = get_dataset( now - 2*output_window_size, tumbling_window_size, output_window_size )\n",
    "    train_X=train_X[train_X.freq1>0]\n",
    "    indices1=list(train_X[train_X.freq1>0].index.values)\n",
    "    train_y=train_y[train_y.index.isin(indices1)]\n",
    "    \n",
    "    #Fitting the Random Forest classifier Model and making predictions with it\n",
    "    modelrf.fit( train_X, train_y )\n",
    "    preds_rf = modelrf.predict(test_X)\n",
    "    \n",
    "    #Fitting the KNN classifier Model and making predictions with it\n",
    "    modelknn.fit( train_X, train_y )\n",
    "    preds_knn = modelknn.predict(test_X)\n",
    "    \n",
    "    #Fitting the SVC Model and making predictions with it\n",
    "    modelsvc.fit( train_X, train_y )\n",
    "    preds_svc = modelsvc.predict(test_X)\n",
    "    \n",
    "    #Calculating metric scores for Random Forest model\n",
    "    accuracyrf = accuracy_score(test_y,preds_rf)\n",
    "    balancedrf = balanced_accuracy_score(test_y,preds_rf)\n",
    "    recallrf = recall_score(test_y,preds_rf)\n",
    "    specificityrf = recall_score(test_y,preds_rf, pos_label = 0)\n",
    "    precisionrf = precision_score(test_y, preds_rf)\n",
    "    \n",
    "    #Appending Random Forest model scores to list\n",
    "    accrf.append(accuracyrf)\n",
    "    balrf.append(balancedrf)\n",
    "    precrf.append(precisionrf)\n",
    "    recrf.append(recallrf)\n",
    "    specrf.append(specificityrf)\n",
    "    \n",
    "    #Calculating metric scores for KNN classifier model\n",
    "    accuracyknn = accuracy_score(test_y,preds_knn)\n",
    "    balancedknn = balanced_accuracy_score(test_y,preds_knn)\n",
    "    recallknn = recall_score(test_y,preds_knn)\n",
    "    specificityknn = recall_score(test_y,preds_knn, pos_label = 0)\n",
    "    precisionknn = precision_score(test_y, preds_knn)\n",
    "    \n",
    "    #Appending KNN scores to list\n",
    "    accknn.append(accuracyknn)\n",
    "    balknn.append(balancedknn)\n",
    "    precknn.append(precisionknn)\n",
    "    recknn.append(recallknn)\n",
    "    specknn.append(specificityknn)\n",
    "    \n",
    "    #Calculating metric scores for SVC model\n",
    "    accuracysvc = accuracy_score(test_y,preds_svc)\n",
    "    balancedsvc = balanced_accuracy_score(test_y,preds_svc)\n",
    "    recallsvc = recall_score(test_y,preds_svc)\n",
    "    specificitysvc = recall_score(test_y,preds_svc, pos_label = 0)\n",
    "    precisionsvc = precision_score(test_y, preds_svc)\n",
    "    \n",
    "    #Appending SVC scores to list\n",
    "    accsvc.append(accuracysvc)\n",
    "    balsvc.append(balancedsvc)\n",
    "    precsvc.append(precisionsvc)\n",
    "    recsvc.append(recallsvc)\n",
    "    specsvc.append(specificitysvc)\n",
    "    \n",
    "    #For next holdout\n",
    "    now = now - output_window_size\n",
    "print('For Random Forest Classifiers ~ Acc. {} Recall: {} Specificity: {} Balanced: {} Precision: {}'.format(np.mean(accrf),np.mean(recrf),np.mean(specrf),np.mean(balrf),np.mean(precrf)))\n",
    "print('For KNN Classifiers ~ Acc. {} Recall: {} Specificity: {} Balanced: {} Precision: {}'.format(np.mean(accknn),np.mean(recknn),np.mean(specknn),np.mean(balknn),np.mean(precknn)))\n",
    "print('For Linear SVC ~ Acc. {} Recall: {} Specificity: {} Balanced: {} Precision: {}'.format(np.mean(accsvc),np.mean(recsvc),np.mean(specsvc),np.mean(balsvc),np.mean(precsvc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forest Classifiers ~ Acc. 0.7714723926380368 Recall: 0.8608374384236454 Specificity: 0.6239837398373984 Balanced: 0.7424105891305219 Precision: 0.7907239819004525\n"
     ]
    }
   ],
   "source": [
    "#Since Random Forest Classifier was my best performing model\n",
    "#Testing on unseen test holdout dataset\n",
    "\n",
    "output_window_size = 30 \n",
    "tumbling_window_size = 30\n",
    "now =  608\n",
    "\n",
    "#Create an estimator of the winning model\n",
    "model = RandomForestClassifier(n_estimators = 100, max_depth=20)\n",
    "\n",
    "#Creating test dataset\n",
    "test_X, test_y = get_dataset( now - output_window_size, tumbling_window_size, output_window_size )\n",
    "\n",
    "test_X=test_X[test_X.freq1>0]\n",
    "indices1=list(test_X[test_X.freq1>0].index.values)\n",
    "test_y=test_y[test_y.index.isin(indices1)]\n",
    "\n",
    "#Creating training dataset\n",
    "train_X, train_y = get_dataset( now - 2*output_window_size, tumbling_window_size, output_window_size )\n",
    "\n",
    "train_X=train_X[train_X.freq1>0]\n",
    "indices1=list(train_X[train_X.freq1>0].index.values)\n",
    "train_y=train_y[train_y.index.isin(indices1)]\n",
    "\n",
    "model.fit( train_X, train_y )\n",
    "preds = pd.DataFrame(model.predict(test_X), columns=['Output'], index=test_X.index.values)\n",
    "\n",
    "#Calculating metric scores for Random Forest model\n",
    "accuracy = accuracy_score(test_y,preds)\n",
    "balanced = balanced_accuracy_score(test_y,preds)\n",
    "recall = recall_score(test_y,preds)\n",
    "specificity = recall_score(test_y,preds, pos_label = 0)\n",
    "precision = precision_score(test_y, preds)\n",
    "\n",
    "print('For Random Forest Classifiers ~ Acc. {} Recall: {} Specificity: {} Balanced: {} Precision: {}'.format(accuracy,recall,specificity,balanced,precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    812\n",
       "0    492\n",
       "Name: output_feature, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([420, 884]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    884\n",
       "0    420\n",
       "Name: Output, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['Output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "      <th>freq3</th>\n",
       "      <th>freq4</th>\n",
       "      <th>freq5</th>\n",
       "      <th>freq6</th>\n",
       "      <th>freq7</th>\n",
       "      <th>qty8</th>\n",
       "      <th>qty9</th>\n",
       "      <th>qty10</th>\n",
       "      <th>qty11</th>\n",
       "      <th>qty12</th>\n",
       "      <th>qty13</th>\n",
       "      <th>qty14</th>\n",
       "      <th>amt15</th>\n",
       "      <th>amt16</th>\n",
       "      <th>amt17</th>\n",
       "      <th>amt18</th>\n",
       "      <th>amt19</th>\n",
       "      <th>amt20</th>\n",
       "      <th>amt21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.291855</td>\n",
       "      <td>3.033937</td>\n",
       "      <td>3.007919</td>\n",
       "      <td>2.839367</td>\n",
       "      <td>2.828054</td>\n",
       "      <td>2.952489</td>\n",
       "      <td>2.875566</td>\n",
       "      <td>33.803167</td>\n",
       "      <td>33.240950</td>\n",
       "      <td>33.826923</td>\n",
       "      <td>32.546380</td>\n",
       "      <td>32.121041</td>\n",
       "      <td>33.994344</td>\n",
       "      <td>32.964932</td>\n",
       "      <td>40.405588</td>\n",
       "      <td>42.115588</td>\n",
       "      <td>33.076527</td>\n",
       "      <td>33.240385</td>\n",
       "      <td>31.044977</td>\n",
       "      <td>7.856505</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.928112</td>\n",
       "      <td>3.146297</td>\n",
       "      <td>3.279875</td>\n",
       "      <td>3.153525</td>\n",
       "      <td>3.000163</td>\n",
       "      <td>3.270376</td>\n",
       "      <td>3.231763</td>\n",
       "      <td>47.207762</td>\n",
       "      <td>48.741694</td>\n",
       "      <td>48.828130</td>\n",
       "      <td>46.955041</td>\n",
       "      <td>46.970582</td>\n",
       "      <td>47.237394</td>\n",
       "      <td>46.070087</td>\n",
       "      <td>51.389362</td>\n",
       "      <td>52.983199</td>\n",
       "      <td>51.924402</td>\n",
       "      <td>55.674863</td>\n",
       "      <td>51.702204</td>\n",
       "      <td>19.108847</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23.070000</td>\n",
       "      <td>25.375000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>58.012500</td>\n",
       "      <td>62.035000</td>\n",
       "      <td>45.860000</td>\n",
       "      <td>48.845000</td>\n",
       "      <td>47.432500</td>\n",
       "      <td>8.385000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>310.040000</td>\n",
       "      <td>404.820000</td>\n",
       "      <td>485.720000</td>\n",
       "      <td>434.130000</td>\n",
       "      <td>389.680000</td>\n",
       "      <td>289.110000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            freq1       freq2       freq3       freq4       freq5       freq6  \\\n",
       "count  884.000000  884.000000  884.000000  884.000000  884.000000  884.000000   \n",
       "mean     3.291855    3.033937    3.007919    2.839367    2.828054    2.952489   \n",
       "std      2.928112    3.146297    3.279875    3.153525    3.000163    3.270376   \n",
       "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "50%      2.000000    2.000000    2.000000    2.000000    2.000000    2.000000   \n",
       "75%      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
       "max     27.000000   25.000000   25.000000   23.000000   23.000000   27.000000   \n",
       "\n",
       "            freq7        qty8        qty9       qty10       qty11       qty12  \\\n",
       "count  884.000000  884.000000  884.000000  884.000000  884.000000  884.000000   \n",
       "mean     2.875566   33.803167   33.240950   33.826923   32.546380   32.121041   \n",
       "std      3.231763   47.207762   48.741694   48.828130   46.955041   46.970582   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000    2.000000    0.000000    2.000000    0.000000    0.000000   \n",
       "50%      2.000000   17.000000   17.000000   17.000000   15.000000   15.500000   \n",
       "75%      4.000000   45.000000   44.000000   45.250000   42.000000   45.000000   \n",
       "max     26.000000  318.000000  512.000000  463.000000  413.000000  421.000000   \n",
       "\n",
       "            qty13       qty14       amt15       amt16       amt17       amt18  \\\n",
       "count  884.000000  884.000000  884.000000  884.000000  884.000000  884.000000   \n",
       "mean    33.994344   32.964932   40.405588   42.115588   33.076527   33.240385   \n",
       "std     47.237394   46.070087   51.389362   52.983199   51.924402   55.674863   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     17.000000   18.000000   23.070000   25.375000   12.750000    0.000000   \n",
       "75%     46.000000   45.000000   58.012500   62.035000   45.860000   48.845000   \n",
       "max    373.000000  349.000000  310.040000  404.820000  485.720000  434.130000   \n",
       "\n",
       "            amt19       amt20  amt21  \n",
       "count  884.000000  884.000000  884.0  \n",
       "mean    31.044977    7.856505    0.0  \n",
       "std     51.702204   19.108847    0.0  \n",
       "min      0.000000    0.000000    0.0  \n",
       "25%      0.000000    0.000000    0.0  \n",
       "50%      0.000000    0.000000    0.0  \n",
       "75%     47.432500    8.385000    0.0  \n",
       "max    389.680000  289.110000    0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying characteristics of customers predicted to stay active\n",
    "pd.options.display.max_columns = None\n",
    "indices_active_preds=list(preds[preds['Output']==1].index.values)\n",
    "test_X[test_X.index.isin(indices_active_preds)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "      <th>freq3</th>\n",
       "      <th>freq4</th>\n",
       "      <th>freq5</th>\n",
       "      <th>freq6</th>\n",
       "      <th>freq7</th>\n",
       "      <th>qty8</th>\n",
       "      <th>qty9</th>\n",
       "      <th>qty10</th>\n",
       "      <th>qty11</th>\n",
       "      <th>qty12</th>\n",
       "      <th>qty13</th>\n",
       "      <th>qty14</th>\n",
       "      <th>amt15</th>\n",
       "      <th>amt16</th>\n",
       "      <th>amt17</th>\n",
       "      <th>amt18</th>\n",
       "      <th>amt19</th>\n",
       "      <th>amt20</th>\n",
       "      <th>amt21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.135714</td>\n",
       "      <td>0.269048</td>\n",
       "      <td>0.211905</td>\n",
       "      <td>0.204762</td>\n",
       "      <td>0.207143</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.188095</td>\n",
       "      <td>1.935714</td>\n",
       "      <td>2.411905</td>\n",
       "      <td>2.259524</td>\n",
       "      <td>2.435714</td>\n",
       "      <td>2.435714</td>\n",
       "      <td>1.885714</td>\n",
       "      <td>2.845238</td>\n",
       "      <td>3.062429</td>\n",
       "      <td>2.645595</td>\n",
       "      <td>1.784881</td>\n",
       "      <td>1.418143</td>\n",
       "      <td>0.994762</td>\n",
       "      <td>0.332524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.771299</td>\n",
       "      <td>0.599518</td>\n",
       "      <td>0.561579</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.486031</td>\n",
       "      <td>0.348221</td>\n",
       "      <td>0.458649</td>\n",
       "      <td>6.033966</td>\n",
       "      <td>7.015792</td>\n",
       "      <td>7.709943</td>\n",
       "      <td>8.230171</td>\n",
       "      <td>6.549475</td>\n",
       "      <td>6.707762</td>\n",
       "      <td>9.549387</td>\n",
       "      <td>11.999898</td>\n",
       "      <td>8.477545</td>\n",
       "      <td>7.614256</td>\n",
       "      <td>6.917893</td>\n",
       "      <td>5.163256</td>\n",
       "      <td>2.899398</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>131.140000</td>\n",
       "      <td>66.540000</td>\n",
       "      <td>93.580000</td>\n",
       "      <td>71.810000</td>\n",
       "      <td>47.490000</td>\n",
       "      <td>46.900000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            freq1       freq2       freq3       freq4       freq5       freq6  \\\n",
       "count  420.000000  420.000000  420.000000  420.000000  420.000000  420.000000   \n",
       "mean     1.135714    0.269048    0.211905    0.204762    0.207143    0.121429   \n",
       "std      0.771299    0.599518    0.561579    0.474632    0.486031    0.348221   \n",
       "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max     15.000000    5.000000    5.000000    3.000000    3.000000    2.000000   \n",
       "\n",
       "            freq7        qty8        qty9       qty10       qty11       qty12  \\\n",
       "count  420.000000  420.000000  420.000000  420.000000  420.000000  420.000000   \n",
       "mean     0.188095    1.935714    2.411905    2.259524    2.435714    2.435714   \n",
       "std      0.458649    6.033966    7.015792    7.709943    8.230171    6.549475   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      3.000000   57.000000   50.000000   73.000000   66.000000   61.000000   \n",
       "\n",
       "            qty13       qty14       amt15       amt16       amt17       amt18  \\\n",
       "count  420.000000  420.000000  420.000000  420.000000  420.000000  420.000000   \n",
       "mean     1.885714    2.845238    3.062429    2.645595    1.784881    1.418143   \n",
       "std      6.707762    9.549387   11.999898    8.477545    7.614256    6.917893   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max     55.000000   76.000000  131.140000   66.540000   93.580000   71.810000   \n",
       "\n",
       "            amt19       amt20  amt21  \n",
       "count  420.000000  420.000000  420.0  \n",
       "mean     0.994762    0.332524    0.0  \n",
       "std      5.163256    2.899398    0.0  \n",
       "min      0.000000    0.000000    0.0  \n",
       "25%      0.000000    0.000000    0.0  \n",
       "50%      0.000000    0.000000    0.0  \n",
       "75%      0.000000    0.000000    0.0  \n",
       "max     47.490000   46.900000    0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying characteristics of customers predicted to churn\n",
    "pd.options.display.max_columns = None\n",
    "indices_churn_preds=list(preds[preds['Output']==0].index.values)\n",
    "test_X[test_X.index.isin(indices_churn_preds)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "      <th>freq3</th>\n",
       "      <th>freq4</th>\n",
       "      <th>freq5</th>\n",
       "      <th>freq6</th>\n",
       "      <th>freq7</th>\n",
       "      <th>qty8</th>\n",
       "      <th>qty9</th>\n",
       "      <th>qty10</th>\n",
       "      <th>qty11</th>\n",
       "      <th>qty12</th>\n",
       "      <th>qty13</th>\n",
       "      <th>qty14</th>\n",
       "      <th>amt15</th>\n",
       "      <th>amt16</th>\n",
       "      <th>amt17</th>\n",
       "      <th>amt18</th>\n",
       "      <th>amt19</th>\n",
       "      <th>amt20</th>\n",
       "      <th>amt21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.000000</td>\n",
       "      <td>812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.376847</td>\n",
       "      <td>3.098522</td>\n",
       "      <td>3.099754</td>\n",
       "      <td>2.899015</td>\n",
       "      <td>2.846059</td>\n",
       "      <td>2.961823</td>\n",
       "      <td>2.908867</td>\n",
       "      <td>34.408867</td>\n",
       "      <td>34.178571</td>\n",
       "      <td>34.112069</td>\n",
       "      <td>33.433498</td>\n",
       "      <td>32.815271</td>\n",
       "      <td>33.740148</td>\n",
       "      <td>32.891626</td>\n",
       "      <td>40.237672</td>\n",
       "      <td>41.909015</td>\n",
       "      <td>32.774347</td>\n",
       "      <td>33.869224</td>\n",
       "      <td>31.528116</td>\n",
       "      <td>8.090739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.041571</td>\n",
       "      <td>3.257187</td>\n",
       "      <td>3.363128</td>\n",
       "      <td>3.240412</td>\n",
       "      <td>3.088852</td>\n",
       "      <td>3.344174</td>\n",
       "      <td>3.319274</td>\n",
       "      <td>48.468306</td>\n",
       "      <td>49.667366</td>\n",
       "      <td>49.920884</td>\n",
       "      <td>47.760518</td>\n",
       "      <td>47.918759</td>\n",
       "      <td>48.404509</td>\n",
       "      <td>47.354221</td>\n",
       "      <td>52.641999</td>\n",
       "      <td>53.548029</td>\n",
       "      <td>52.657013</td>\n",
       "      <td>56.104911</td>\n",
       "      <td>52.848800</td>\n",
       "      <td>19.571244</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>21.190000</td>\n",
       "      <td>24.470000</td>\n",
       "      <td>11.265000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>58.965000</td>\n",
       "      <td>62.300000</td>\n",
       "      <td>45.582500</td>\n",
       "      <td>51.155000</td>\n",
       "      <td>48.567500</td>\n",
       "      <td>8.457500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>310.040000</td>\n",
       "      <td>404.820000</td>\n",
       "      <td>485.720000</td>\n",
       "      <td>434.130000</td>\n",
       "      <td>389.680000</td>\n",
       "      <td>289.110000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            freq1       freq2       freq3       freq4       freq5       freq6  \\\n",
       "count  812.000000  812.000000  812.000000  812.000000  812.000000  812.000000   \n",
       "mean     3.376847    3.098522    3.099754    2.899015    2.846059    2.961823   \n",
       "std      3.041571    3.257187    3.363128    3.240412    3.088852    3.344174   \n",
       "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000    1.000000    1.000000    1.000000    1.000000    0.000000   \n",
       "50%      2.000000    2.000000    2.000000    2.000000    2.000000    2.000000   \n",
       "75%      4.000000    4.000000    4.000000    4.000000    4.000000    4.000000   \n",
       "max     27.000000   25.000000   25.000000   23.000000   23.000000   27.000000   \n",
       "\n",
       "            freq7        qty8        qty9       qty10       qty11       qty12  \\\n",
       "count  812.000000  812.000000  812.000000  812.000000  812.000000  812.000000   \n",
       "mean     2.908867   34.408867   34.178571   34.112069   33.433498   32.815271   \n",
       "std      3.319274   48.468306   49.667366   49.920884   47.760518   47.918759   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      2.000000   17.000000   18.000000   16.000000   15.000000   16.000000   \n",
       "75%      4.000000   47.000000   45.250000   47.000000   44.250000   45.000000   \n",
       "max     26.000000  318.000000  512.000000  463.000000  413.000000  421.000000   \n",
       "\n",
       "            qty13       qty14       amt15       amt16       amt17       amt18  \\\n",
       "count  812.000000  812.000000  812.000000  812.000000  812.000000  812.000000   \n",
       "mean    33.740148   32.891626   40.237672   41.909015   32.774347   33.869224   \n",
       "std     48.404509   47.354221   52.641999   53.548029   52.657013   56.104911   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     15.500000   16.000000   21.190000   24.470000   11.265000    0.000000   \n",
       "75%     46.000000   46.000000   58.965000   62.300000   45.582500   51.155000   \n",
       "max    373.000000  349.000000  310.040000  404.820000  485.720000  434.130000   \n",
       "\n",
       "            amt19       amt20  amt21  \n",
       "count  812.000000  812.000000  812.0  \n",
       "mean    31.528116    8.090739    0.0  \n",
       "std     52.848800   19.571244    0.0  \n",
       "min      0.000000    0.000000    0.0  \n",
       "25%      0.000000    0.000000    0.0  \n",
       "50%      0.000000    0.000000    0.0  \n",
       "75%     48.567500    8.457500    0.0  \n",
       "max    389.680000  289.110000    0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying characteristics of customers that stay active in reality\n",
    "pd.options.display.max_columns = None\n",
    "indices_active_actual=list(test_y[test_y==1].index.values)\n",
    "test_X[test_X.index.isin(indices_active_actual)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq1</th>\n",
       "      <th>freq2</th>\n",
       "      <th>freq3</th>\n",
       "      <th>freq4</th>\n",
       "      <th>freq5</th>\n",
       "      <th>freq6</th>\n",
       "      <th>freq7</th>\n",
       "      <th>qty8</th>\n",
       "      <th>qty9</th>\n",
       "      <th>qty10</th>\n",
       "      <th>qty11</th>\n",
       "      <th>qty12</th>\n",
       "      <th>qty13</th>\n",
       "      <th>qty14</th>\n",
       "      <th>amt15</th>\n",
       "      <th>amt16</th>\n",
       "      <th>amt17</th>\n",
       "      <th>amt18</th>\n",
       "      <th>amt19</th>\n",
       "      <th>amt20</th>\n",
       "      <th>amt21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.310976</td>\n",
       "      <td>0.567073</td>\n",
       "      <td>0.469512</td>\n",
       "      <td>0.491870</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.520325</td>\n",
       "      <td>0.526423</td>\n",
       "      <td>5.599593</td>\n",
       "      <td>5.376016</td>\n",
       "      <td>6.408537</td>\n",
       "      <td>5.378049</td>\n",
       "      <td>5.634146</td>\n",
       "      <td>7.004065</td>\n",
       "      <td>7.373984</td>\n",
       "      <td>8.804411</td>\n",
       "      <td>8.762622</td>\n",
       "      <td>6.862866</td>\n",
       "      <td>5.037215</td>\n",
       "      <td>4.594980</td>\n",
       "      <td>1.047012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.824054</td>\n",
       "      <td>1.009917</td>\n",
       "      <td>1.072279</td>\n",
       "      <td>1.068878</td>\n",
       "      <td>1.163927</td>\n",
       "      <td>1.339359</td>\n",
       "      <td>1.187731</td>\n",
       "      <td>15.155146</td>\n",
       "      <td>16.535553</td>\n",
       "      <td>17.918626</td>\n",
       "      <td>17.021233</td>\n",
       "      <td>16.171821</td>\n",
       "      <td>18.249571</td>\n",
       "      <td>17.625846</td>\n",
       "      <td>22.068995</td>\n",
       "      <td>24.319562</td>\n",
       "      <td>21.613769</td>\n",
       "      <td>22.011503</td>\n",
       "      <td>16.963263</td>\n",
       "      <td>5.748623</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.455000</td>\n",
       "      <td>4.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>177.910000</td>\n",
       "      <td>226.630000</td>\n",
       "      <td>225.530000</td>\n",
       "      <td>341.730000</td>\n",
       "      <td>176.260000</td>\n",
       "      <td>68.810000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            freq1       freq2       freq3       freq4       freq5       freq6  \\\n",
       "count  492.000000  492.000000  492.000000  492.000000  492.000000  492.000000   \n",
       "mean     1.310976    0.567073    0.469512    0.491870    0.560976    0.520325   \n",
       "std      0.824054    1.009917    1.072279    1.068878    1.163927    1.339359   \n",
       "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      9.000000    8.000000   13.000000   14.000000   13.000000   19.000000   \n",
       "\n",
       "            freq7        qty8        qty9       qty10       qty11       qty12  \\\n",
       "count  492.000000  492.000000  492.000000  492.000000  492.000000  492.000000   \n",
       "mean     0.526423    5.599593    5.376016    6.408537    5.378049    5.634146   \n",
       "std      1.187731   15.155146   16.535553   17.918626   17.021233   16.171821   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    3.000000    1.000000    5.000000    2.250000    3.000000   \n",
       "max     14.000000  176.000000  232.000000  235.000000  261.000000  188.000000   \n",
       "\n",
       "            qty13       qty14       amt15       amt16       amt17       amt18  \\\n",
       "count  492.000000  492.000000  492.000000  492.000000  492.000000  492.000000   \n",
       "mean     7.004065    7.373984    8.804411    8.762622    6.862866    5.037215   \n",
       "std     18.249571   17.625846   22.068995   24.319562   21.613769   22.011503   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      4.000000    5.000000    6.455000    4.640000    0.000000    0.000000   \n",
       "max    195.000000  163.000000  177.910000  226.630000  225.530000  341.730000   \n",
       "\n",
       "            amt19       amt20  amt21  \n",
       "count  492.000000  492.000000  492.0  \n",
       "mean     4.594980    1.047012    0.0  \n",
       "std     16.963263    5.748623    0.0  \n",
       "min      0.000000    0.000000    0.0  \n",
       "25%      0.000000    0.000000    0.0  \n",
       "50%      0.000000    0.000000    0.0  \n",
       "75%      0.000000    0.000000    0.0  \n",
       "max    176.260000   68.810000    0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying characteristics of customers that churn in reality\n",
    "pd.options.display.max_columns = None\n",
    "indices_churn_actual=list(test_y[test_y==0].index.values)\n",
    "test_X[test_X.index.isin(indices_churn_actual)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Churners v Active count\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "labels = ['churners','active']\n",
    "values = [len(preds[preds['Output']==0]), len(preds[preds['Output']==1])]\n",
    "plt.bar([0, 1], values, align='center', color=['blue', 'green'])\n",
    "plt.xticks([0, 1], labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparison based on frequency of store visits\n",
    "x=test_X[test_X.index.isin(indices_active_preds)]\n",
    "y=test_X[test_X.index.isin(indices_churn_preds)]\n",
    "Freq_mean=[y['freq1'].mean(),x['freq1'].mean()]\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "labels = ['churners','active']\n",
    "values = Freq_mean\n",
    "plt.bar([0, 1], values, align='center', color=['blue', 'orange'])\n",
    "plt.xticks([0, 1], labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparison based on average spend\n",
    "x=test_X[test_X.index.isin(indices_active_preds)]\n",
    "y=test_X[test_X.index.isin(indices_churn_preds)]\n",
    "Freq_mean=[y['amt15'].mean(),x['amt15'].mean()]\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "labels = ['churners','active']\n",
    "values = Freq_mean\n",
    "plt.bar([0, 1], values, align='center', color=['blue', 'orange'])\n",
    "plt.xticks([0, 1], labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparison based on average quantities purchased\n",
    "x=test_X[test_X.index.isin(indices_active_preds)]\n",
    "y=test_X[test_X.index.isin(indices_churn_preds)]\n",
    "Freq_mean=[y['qty8'].mean(),x['qty8'].mean()]\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "labels = ['churners','active']\n",
    "values = Freq_mean\n",
    "plt.bar([0, 1], values, align='center', color=['blue', 'orange'])\n",
    "plt.xticks([0, 1], labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function definition to return test holdout\n",
    "def get_testholdout( ref_day = 608-30, tumbling_window_size = 30, num_periods = 7, window_agg_fun = 'SUM'):\n",
    "        sql_top = \"\"\"\n",
    "        SELECT cust,\n",
    "        %(ref_date)s AS ref_day,\n",
    "        \"\"\"\n",
    "       \n",
    "        sql=sql_top\n",
    "#Creating temporal features to account for FREQUENCY of visits, QUANTITY of items, AMOUNT spent\n",
    "        for i in range(0,num_periods):\n",
    "            sql += \"{2}(CASE WHEN dayofpurchase > %(ref_date)s -%(ws)s::INT*({0}+1) AND dayofpurchase <= %(ref_date)s-%(ws)s*({0}) THEN 1 ELSE 0 END ) as freq{1},\\n\".format(i, i+1, window_agg_fun)\n",
    "        for i in range(num_periods,num_periods*2):\n",
    "            sql += \"{2}(CASE WHEN dayofpurchase > %(ref_date)s -%(ws)s::INT*({0}+1) AND dayofpurchase <= %(ref_date)s-%(ws)s*({0}) THEN qty::INT ELSE 0 END ) as qty{1},\\n\".format(i, i+1, window_agg_fun)\n",
    "        for i in range(num_periods*2,num_periods*3):\n",
    "            sql += \"{2}(CASE WHEN dayofpurchase > %(ref_date)s -%(ws)s::INT*({0}+1) AND dayofpurchase <= %(ref_date)s-%(ws)s*({0}) THEN val ELSE 0 END ) as amt{1},\\n\".format(i, i+1, window_agg_fun)\n",
    "\n",
    "        sql_bottom = \"\"\"\n",
    "        FROM temp_features\n",
    "        GROUP BY cust\n",
    "        \"\"\"    \n",
    "        sql = sql[:-2] + sql_bottom\n",
    "        with psycopg2.connect(\"host='{}' dbname='nlab' user='{}' password='{}'\".format(db_ip, user, pw)) as conn:\n",
    "            df = pd.read_sql(sql, conn, params = {'ref_date':ref_day,'ws':tumbling_window_size})\n",
    "            df=df.set_index('cust')\n",
    "            return df.drop(columns = ['ref_day'], inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Predictor Model\n",
    "#Function definition that returns the predictions when called\n",
    "#Since Random Forest Classifiers were my best performing model\n",
    "\n",
    "def predictions(ref_day = 608, tumbling_window_size = 30, output_window_size = 7):\n",
    "\n",
    "#Create an estimator of the winning model\n",
    "    model = RandomForestClassifier(n_estimators = 100, max_depth=20)\n",
    "\n",
    "#Creating training dataset\n",
    "    train_X, train_y = get_dataset( ref_day - 2*output_window_size, tumbling_window_size, output_window_size )\n",
    "    train_X=train_X[train_X.freq1>0]\n",
    "    indices1=list(train_X[train_X.freq1>0].index.values)\n",
    "    train_y=train_y[train_y.index.isin(indices1)]\n",
    "\n",
    "    model.fit( train_X, train_y )\n",
    "    test_X = get_testholdout( ref_day - output_window_size, tumbling_window_size)\n",
    "\n",
    "    test_X=test_X[test_X.freq1>0]\n",
    "#Final predictions\n",
    "    preds = pd.DataFrame(model.predict(test_X), columns=['Output'], index=test_X.index.values)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set ref_day to the day of prediction before executing\n",
    "df=predictions(ref_day = 608, tumbling_window_size = 30, output_window_size = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16213</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16221</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16263</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16273</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16283</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1244 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Output\n",
       "39          0\n",
       "47          0\n",
       "55          1\n",
       "76          1\n",
       "86          0\n",
       "...       ...\n",
       "16213       1\n",
       "16221       0\n",
       "16263       1\n",
       "16273       0\n",
       "16283       1\n",
       "\n",
       "[1244 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returning set of predictions for the active customers\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
